# Entrega Proyecto Parte 1 Sistemas DistribuÃ­dos ðŸš—ðŸ“Š

## Importante 
Actualmente te encuentras en nuestra rama main donde armamos el codigo principal.
Sin embargo, en honor a los distintos tipos de cache implementados con sus respectivos distintos generadores de trÃ¡fico, se crearon 4 ramas en total: 

rama_cacheP1: Sistema de remociÃ³n del cache -> LRU - 50mb
              DistribucÃ­on generador de trÃ¡fico -> Poisson
rama_cacheP2: Sistema de remociÃ³n del cache -> LFU - 100mb
              DistribucÃ­on generador de trÃ¡fico -> Poisson
rama_cacheZ1: Sistema de remociÃ³n del cache -> LRU - 50mb
              DistribucÃ­on generador de trÃ¡fico -> Zipf
rama_cacheP1: Sistema de remociÃ³n del cache -> LFU - 100mb
              DistribucÃ­on generador de trÃ¡fico -> Zipf

Cada una de estas ramas tiene exactamente la misma estructura, solo se hicieron los cambios correpondientes en docker-compose.yml para el tipo de cache y tamaÃ±o, y los cambios correspondientes en gdt.py para el tipo de distribuciÃ³n seguida por el generador de trÃ¡fico.

## Arquitectura General

El sistema consta de los siguientes componentes:

- **Scraper**: Obtiene eventos de trÃ¡fico (como accidentes, atascos, etc.) desde la API pÃºblica del mapa en vivo de Waze. Guarda los eventos Ãºnicos en MongoDB.
- **Base de Datos (MongoDB)**: Almacena de manera persistente los eventos capturados por el scraper.
- **CachÃ© (Flask + Redis)**: Expone una API REST para consultar eventos por UUID y guarda resultados temporalmente para acelerar accesos repetidos.
- **Generador de TrÃ¡fico**: Simula consultas concurrentes al sistema usando distribuciones probabilÃ­sticas (por ejemplo, Poisson), evaluando el comportamiento de la cachÃ© y la base de datos.
- **Docker Compose**: Orquesta el despliegue de todos los servicios en contenedores separados, facilitando su ejecuciÃ³n conjunta.

---

##  Requisitos

- Docker
- Docker Compose
- Git

## ðŸš€ EjecuciÃ³n del sistema

1. Clona el repositorio

```bash
# Clona el repositorio
git clone https://github.com/tu-usuario/ProyectoSD.git.
cd ProyectoSD

# Levanta los servicios con Docker
sudo docker-compose up --build

# Si se quiere ejecutar otra vez sin haber hecho cambios en el codigo
sudo docker-compose up


```

El scraper se ejecutarÃ¡ y guardarÃ¡ los datos en formato JSON en el contenedor como volumen para que se mantengan guardados.
Se levvantaran todos los contenedores y se realizaran consultas en seguida al sistema.

## ðŸ“‚ Estructura del proyecto
```bash
.
â”œâ”€â”€ scraper/              # Scraper de eventos desde Waze
â”‚   â””â”€â”€ scraper.py
    â””â”€â”€ Dockerfile
    â””â”€â”€ requirements.txt
â”œâ”€â”€ cache/                # Servidor Flask + Redis como cachÃ©
â”‚   â””â”€â”€ cache.py
    â””â”€â”€ Dockerfile
â”œâ”€â”€ generador_trafico/    # Simula trÃ¡fico usando distribuciÃ³n de Poisson
â”‚   â””â”€â”€ generador.py
    â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml    # OrquestaciÃ³n de contenedores
â””â”€â”€ README.md             # Este archivo

```
## ðŸ›  TecnologÃ­as utilizadas

    Python (scraping, servidor REST, generaciÃ³n de trÃ¡fico)

    MongoDB (almacenamiento persistente)

    Redis (sistema de cachÃ© con TTL parametrizable)

    Flask (API REST para interacciÃ³n entre mÃ³dulos)

    Docker & Docker Compose (despliegue modular)

## Estado actual

âœ” Scraper funcional conectado a MongoDB
âœ” API REST con cachÃ© y TTL configurable
âœ” Generador de carga que simula trÃ¡fico realista
âœ” Sistema completamente containerizado
âœ” DocumentaciÃ³n tÃ©cnica en LaTeX incluida

## ðŸ“Œ Notas

- El scraping solo obtiene datos visibles en el mapa en vivo al momento de ejecuciÃ³n.
- La base de datos aun no esta subida de forma remota a mongo, solo la manejamos de forma local

## Autoras 

Isidora Gonzalez
Natalia Ortega


